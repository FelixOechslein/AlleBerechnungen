{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b196d4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import nbinom, binom, poisson\n",
    "from statsmodels.discrete.count_model import ZeroInflatedNegativeBinomialP\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import math\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import kendalltau\n",
    "from scipy.stats import spearmanr\n",
    "import os\n",
    "from scipy.optimize import minimize, Bounds, LinearConstraint, NonlinearConstraint\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d7f24c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:/Users/felix.oechslein/Desktop/Analysen Thalia, Mai/verarbeitete_daten'\n",
    "filename = 'Pivot_Trans_Privat_ohneApple_Langzeitkunde.csv'\n",
    "\n",
    "df_trans_werte = pd.read_csv(os.path.join(path, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4d1d8cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:/Users/felix.oechslein/Desktop/Analysen Thalia, Mai/verarbeitete_daten'\n",
    "filename = 'Pivot_LY_Privat_ohneApple_Langzeitkunde.csv'\n",
    "\n",
    "df_LY = pd.read_csv(os.path.join(path, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1c371a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:/Users/felix.oechslein/Desktop/Analysen Thalia, Mai/verarbeitete_daten'\n",
    "filename = 'Pivot_HY_Privat_ohneApple_Langzeitkunde.csv'\n",
    "\n",
    "df_HY = pd.read_csv(os.path.join(path, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1fcaab9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:/Users/felix.oechslein/Desktop/Analysen Thalia, Mai/verarbeitete_daten'\n",
    "filename = 'Pivot_NO_Privat_ohneApple_Langzeitkunde.csv'\n",
    "\n",
    "df_NO_werte = pd.read_csv(os.path.join(path, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "68ae15da",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:/Users/felix.oechslein/Desktop/Analysen Thalia, Mai/verarbeitete_daten'\n",
    "filename = 'Pivot_LO_Privat_ohneApple_Langzeitkunde.csv'\n",
    "\n",
    "df_LO = pd.read_csv(os.path.join(path, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "62c55e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Alle DataFrame Werte von Float zu int\n",
    "df_trans_werte = df_trans_werte.astype(int)\n",
    "df_LY = df_LY.astype(int)\n",
    "df_HY = df_HY.astype(int)\n",
    "df_NO_werte = df_NO_werte.astype(int)\n",
    "df_LO = df_LO.astype(int)\n",
    "\n",
    "# Transwerte-1 definiert für spätere Berecnungen in der Copula\n",
    "#df_trans_werte_minusEins = df_trans_werte.loc[:, df_NO_werte.columns != 'iid'] -1\n",
    "#df_trans_werte_minusEins = df_trans_werte_minusEins.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "781124ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1462"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_trans_werte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1d382f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1462"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_LY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3dc6152d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "697"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_HY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5e8b7cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "647"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_NO_werte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2b15d1c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "647"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_LO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75901ee7",
   "metadata": {},
   "source": [
    "### Sicherstellen dass alle df dieselben Kunden verwenden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e691c85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entfernen der Zeilen aus df_HY, die nicht in df_trans_werte und df_LO enthalten sind\n",
    "df_HY = df_HY[df_HY['iid'].isin(df_trans_werte['iid'])]\n",
    "df_HY = df_HY[df_HY['iid'].isin(df_LO['iid'])]\n",
    "\n",
    "# Entfernen der Zeilen aus df_trans_werte, die nicht in df_HY, df_NO_werte und df_LY enthalten sind\n",
    "df_trans_werte = df_trans_werte[df_trans_werte['iid'].isin(df_HY['iid'])]\n",
    "df_trans_werte = df_trans_werte[df_trans_werte['iid'].isin(df_NO_werte['iid'])]\n",
    "df_trans_werte = df_trans_werte[df_trans_werte['iid'].isin(df_LY['iid'])]\n",
    "\n",
    "# Entfernen der Zeilen aus df_LO, die nicht in df_HY enthalten sind\n",
    "df_LO = df_LO[df_LO['iid'].isin(df_HY['iid'])]\n",
    "\n",
    "# Entfernen der Zeilen aus df_NO_werte, die nicht in df_trans_werte enthalten sind\n",
    "df_NO_werte = df_NO_werte[df_NO_werte['iid'].isin(df_trans_werte['iid'])]\n",
    "\n",
    "# Entfernen der Zeilen aus df_LY, die nicht in df_trans_werte enthalten sind\n",
    "df_LY = df_LY[df_LY['iid'].isin(df_trans_werte['iid'])]\n",
    "\n",
    "### Alle DataFrames Indizes resetten, damit man sie gemeinsam identifiziere kann\n",
    "df_HY = df_HY.reset_index(drop=True)\n",
    "df_trans_werte = df_trans_werte.reset_index(drop=True)\n",
    "df_LO = df_LO.reset_index(drop=True)\n",
    "df_NO_werte = df_NO_werte.reset_index(drop=True)\n",
    "df_LY = df_LY.reset_index(drop=True)\n",
    "\n",
    "# NO-1 definiert für spätere Berechnung inder Copula\n",
    "df_NO_minusEins = df_NO_werte.copy()\n",
    "df_NO_minusEins.loc[:, df_NO_minusEins.columns != 'iid'] = df_NO_minusEins.loc[:, df_NO_minusEins.columns != 'iid'] -1\n",
    "df_NO_minusEins = df_NO_minusEins.astype(int)\n",
    "# transwerte -1 definiert für spätere Berechnung inder Copula\n",
    "df_trans_werte_minusEins = df_trans_werte.copy()\n",
    "df_trans_werte_minusEins.loc[:, df_trans_werte_minusEins.columns != 'iid'] = df_trans_werte_minusEins.loc[:, df_trans_werte_minusEins.columns != 'iid'] -1\n",
    "df_trans_werte_minusEins = df_trans_werte_minusEins.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "287502e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Siherstellen dass alle dataframes die Kunden in derselben Reihenfolge auflisten\n",
    "df_NO_minusEins = df_NO_minusEins.sort_values('iid')\n",
    "df_HY = df_HY.sort_values('iid')\n",
    "df_trans_werte = df_trans_werte.sort_values('iid')\n",
    "df_LO = df_LO.sort_values('iid')\n",
    "df_NO_werte = df_NO_werte.sort_values('iid')\n",
    "df_LY = df_LY.sort_values('iid')\n",
    "df_trans_werte_minusEins = df_trans_werte_minusEins.sort_values('iid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452a123b",
   "metadata": {},
   "source": [
    "#### Ausreißer bei den Käufen ermitteln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "77d6a17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  4  4  4  4  4  4  4  4  4  4  4  4\n",
      "  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4\n",
      "  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4\n",
      "  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7\n",
      "  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7\n",
      "  7  7  7  7  7  7  7  7  7  7  7  7  7  8  8  8  8  8  8  8  8  8  8  8\n",
      "  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8\n",
      "  8  8  8  8  8  8  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9\n",
      "  9  9  9  9  9  9  9  9  9  9  9  9  9  9 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10 10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 13 13 13 13 13\n",
      " 13 13 13 13 13 13 13 13 14 14 14 14 14 14 15 15 15 15 15 16 16 16 16 16\n",
      " 16 16 17 17 17 17 17 17 17 17 17 17 18 18 19 19 19 19 19 19 20 20 20 21\n",
      " 21 21 22 22 23 23 24 24 24 25 25 28 29 31 32 32 33 34 34 37 43 44 92]\n"
     ]
    }
   ],
   "source": [
    "# Darstellun dergesamte Käufe der Kunden\n",
    "arr = np.sum(df_trans_werte[df_trans_werte.columns[df_trans_werte.columns != 'iid']], axis=1)\n",
    "\n",
    "# Sortiere das Array nach Größe\n",
    "sorted_arr = np.sort(arr)\n",
    "\n",
    "print(sorted_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d4b37484",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gesamtzahl Käufe: 31 Position: 415\n",
      "Gesamtzahl Käufe: 32 Position: 451\n",
      "Gesamtzahl Käufe: 32 Position: 531\n",
      "Gesamtzahl Käufe: 33 Position: 364\n",
      "Gesamtzahl Käufe: 34 Position: 351\n",
      "Gesamtzahl Käufe: 34 Position: 348\n",
      "Gesamtzahl Käufe: 37 Position: 501\n",
      "Gesamtzahl Käufe: 43 Position: 408\n",
      "Gesamtzahl Käufe: 44 Position: 285\n",
      "Gesamtzahl Käufe: 92 Position: 422\n"
     ]
    }
   ],
   "source": [
    "# Finde die Indizes der größten Einträge\n",
    "indices_ausreisser_käufe = np.argsort(arr)[-10:]\n",
    "\n",
    "# Gebe die 10 Zeilen mit den größten Einträgen und deren Positionen aus\n",
    "for index in indices_ausreisser_käufe:\n",
    "    print(\"Gesamtzahl Käufe:\", arr[index], \"Position:\", index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fa8aee",
   "metadata": {},
   "source": [
    "#### Ausreißer bei den Öffungen ermitteln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c65e1009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die drei größten Werte in der Spalte '1' sind:\n",
      "140    3\n",
      "145    3\n",
      "152    3\n",
      "Name: 1, dtype: int32\n",
      "Die zugehörigen Indizes sind:\n",
      "Int64Index([140, 145, 152], dtype='int64')\n",
      "\n",
      "Die drei größten Werte in der Spalte '2' sind:\n",
      "37     3\n",
      "69     3\n",
      "166    3\n",
      "Name: 2, dtype: int32\n",
      "Die zugehörigen Indizes sind:\n",
      "Int64Index([37, 69, 166], dtype='int64')\n",
      "\n",
      "Die drei größten Werte in der Spalte '3' sind:\n",
      "443    5\n",
      "642    3\n",
      "1      2\n",
      "Name: 3, dtype: int32\n",
      "Die zugehörigen Indizes sind:\n",
      "Int64Index([443, 642, 1], dtype='int64')\n",
      "\n",
      "Die drei größten Werte in der Spalte '4' sind:\n",
      "387    8\n",
      "408    5\n",
      "533    4\n",
      "Name: 4, dtype: int32\n",
      "Die zugehörigen Indizes sind:\n",
      "Int64Index([387, 408, 533], dtype='int64')\n",
      "\n",
      "Die drei größten Werte in der Spalte '5' sind:\n",
      "35    3\n",
      "75    3\n",
      "87    3\n",
      "Name: 5, dtype: int32\n",
      "Die zugehörigen Indizes sind:\n",
      "Int64Index([35, 75, 87], dtype='int64')\n",
      "\n",
      "Die drei größten Werte in der Spalte '6' sind:\n",
      "8     4\n",
      "9     4\n",
      "43    4\n",
      "Name: 6, dtype: int32\n",
      "Die zugehörigen Indizes sind:\n",
      "Int64Index([8, 9, 43], dtype='int64')\n",
      "\n",
      "Die drei größten Werte in der Spalte '7' sind:\n",
      "408    3\n",
      "536    3\n",
      "1      2\n",
      "Name: 7, dtype: int32\n",
      "Die zugehörigen Indizes sind:\n",
      "Int64Index([408, 536, 1], dtype='int64')\n",
      "\n",
      "Die drei größten Werte in der Spalte '8' sind:\n",
      "229    3\n",
      "360    3\n",
      "485    3\n",
      "Name: 8, dtype: int32\n",
      "Die zugehörigen Indizes sind:\n",
      "Int64Index([229, 360, 485], dtype='int64')\n",
      "\n",
      "Die drei größten Werte in der Spalte '9' sind:\n",
      "500    3\n",
      "1      2\n",
      "8      2\n",
      "Name: 9, dtype: int32\n",
      "Die zugehörigen Indizes sind:\n",
      "Int64Index([500, 1, 8], dtype='int64')\n",
      "\n",
      "Die drei größten Werte in der Spalte '10' sind:\n",
      "6    2\n",
      "1    1\n",
      "3    1\n",
      "Name: 10, dtype: int32\n",
      "Die zugehörigen Indizes sind:\n",
      "Int64Index([6, 1, 3], dtype='int64')\n",
      "\n",
      "Die drei größten Werte in der Spalte '11' sind:\n",
      "523    3\n",
      "54     2\n",
      "0      1\n",
      "Name: 11, dtype: int32\n",
      "Die zugehörigen Indizes sind:\n",
      "Int64Index([523, 54, 0], dtype='int64')\n",
      "\n",
      "Die drei größten Werte in der Spalte '12' sind:\n",
      "65     3\n",
      "166    3\n",
      "174    3\n",
      "Name: 12, dtype: int32\n",
      "Die zugehörigen Indizes sind:\n",
      "Int64Index([65, 166, 174], dtype='int64')\n",
      "\n",
      "Die drei größten Werte in der Spalte '13' sind:\n",
      "76     3\n",
      "485    3\n",
      "1      2\n",
      "Name: 13, dtype: int32\n",
      "Die zugehörigen Indizes sind:\n",
      "Int64Index([76, 485, 1], dtype='int64')\n",
      "\n",
      "Die drei größten Werte in der Spalte '14' sind:\n",
      "286    4\n",
      "1      3\n",
      "3      3\n",
      "Name: 14, dtype: int32\n",
      "Die zugehörigen Indizes sind:\n",
      "Int64Index([286, 1, 3], dtype='int64')\n",
      "\n",
      "Die drei größten Werte in der Spalte '15' sind:\n",
      "9      2\n",
      "123    2\n",
      "196    2\n",
      "Name: 15, dtype: int32\n",
      "Die zugehörigen Indizes sind:\n",
      "Int64Index([9, 123, 196], dtype='int64')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for column in df_NO_werte.columns[df_NO_werte.columns != 'iid']:\n",
    "    largest_values = df_NO_werte[column].nlargest(3)\n",
    "    print(f\"Die drei größten Werte in der Spalte '{column}' sind:\")\n",
    "    print(largest_values)\n",
    "    print(\"Die zugehörigen Indizes sind:\")\n",
    "    print(largest_values.index)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "33688978",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_ausreisser_öffnungen = [443, 387, 408]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1480ee7",
   "metadata": {},
   "source": [
    "## Ausreißer bei den Kunden löschen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d45089e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([443, 387, 408, 415, 451, 531, 364, 351, 348, 501, 408, 285, 422],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ausreißer Käufe = indices_ausreisser_käufe\n",
    "# Ausreißer Öffungen = indices_ausreisser_öffnungen\n",
    "ausreisser_pos = np.concatenate([indices_ausreisser_öffnungen, indices_ausreisser_käufe])\n",
    "ausreisser_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "950add22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zeilen löschen\n",
    "df_NO_minusEins = df_NO_minusEins.drop(ausreisser_pos).reset_index(drop = True)\n",
    "df_HY = df_HY.drop(ausreisser_pos).reset_index(drop = True)\n",
    "df_trans_werte = df_trans_werte.drop(ausreisser_pos).reset_index(drop = True)\n",
    "df_LO = df_LO.drop(ausreisser_pos).reset_index(drop = True)\n",
    "df_NO_werte = df_NO_werte.drop(ausreisser_pos).reset_index(drop = True)\n",
    "df_LY = df_LY.drop(ausreisser_pos).reset_index(drop = True)\n",
    "df_trans_werte_minusEins = df_trans_werte_minusEins.drop(ausreisser_pos).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6b4194",
   "metadata": {},
   "source": [
    "## Spezifikation des Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fb05ab22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "635"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anzahl_kunden = len(df_trans_werte[\"iid\"])\n",
    "anzahl_kunden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e71e572f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anzahl_monate = len(df_trans_werte.columns[df_trans_werte.columns != 'iid'])\n",
    "anzahl_monate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "97faae5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "anzahl_states = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f59f07b",
   "metadata": {},
   "source": [
    "##### Definition der Transitionmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1430b8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition der Erfolgswahrscheinlichkeit p_t als 1 x anzhal_kunden array \n",
    "def Q_v_state_t_minusEins_state_t_monat(alpha, gamma, state_t_minusEins, state, monat):\n",
    "    \n",
    "    state_t_minusEins = state_t_minusEins -1\n",
    "    state = state -1\n",
    "    str_monat = str(monat)\n",
    "    \n",
    "    # Definition der X_t_minusEins\n",
    "    # verwendete Parameter\n",
    "    EM_monat_minusEins = df_HY[str_monat]\n",
    "    Y_monat_minusEins = df_trans_werte[str_monat]\n",
    "    O_monat_minusEins = df_NO_werte[str_monat]\n",
    "    # Definition\n",
    "    X_t_minusEins = [O_monat_minusEins.apply(lambda x: int(x > 0)),\\\n",
    "                     Y_monat_minusEins.apply(lambda x: int(x > 0)),\\\n",
    "                     EM_monat_minusEins, np.square(EM_monat_minusEins)]\n",
    "    \n",
    "    X_t_minusEins = np.array(X_t_minusEins)\n",
    "    array_v = alpha[anzahl_states*state_t_minusEins + state] +\\\n",
    "                    gamma[anzahl_states*state_t_minusEins + state] * X_t_minusEins[0] +\\\n",
    "                    gamma[(np.square(anzahl_states)) + anzahl_states*state_t_minusEins + state] * X_t_minusEins[1] +\\\n",
    "                    gamma[(2* np.square(anzahl_states)) + anzahl_states*state_t_minusEins + state] * X_t_minusEins[2] +\\\n",
    "                    gamma[(3* np.square(anzahl_states)) + anzahl_states*state_t_minusEins + state] * X_t_minusEins[3]\n",
    "\n",
    "    return array_v\n",
    "\n",
    "# Definition der Transitionmatrix\n",
    "def probability_Q_state_monat(alpha, gamma):\n",
    "    \n",
    "    ### Erstellung leerer anzahl_states x anzahl_states arrays für jeden Kunden und jeden Monat\n",
    "    Q = np.zeros((anzahl_kunden, anzahl_monate - 1, anzahl_states, anzahl_states))\n",
    "                \n",
    "    for monat in range(2, anzahl_monate + 1):\n",
    "        \n",
    "        for state_t_minusEins in range(1, anzahl_states +1):\n",
    "            \n",
    "            # Erste Spalte besteht aus Nullen, da eine Trasition zurück in state 1 nicht möglich ist\n",
    "            for state in range(2, anzahl_states +1):\n",
    "                \n",
    "                q_array_iid_monat_state = Q_v_state_t_minusEins_state_t_monat(alpha, gamma, state_t_minusEins, state, monat)\n",
    "\n",
    "                # Speicherung der Werte in den leeren arrays\n",
    "                for iid in range(0, anzahl_kunden):\n",
    "                    \n",
    "                    #Neue Definition ohne die Verwedung von Namen\n",
    "                    Q[iid, monat-2, state_t_minusEins-1, state-1] = q_array_iid_monat_state[iid]\n",
    "                    \n",
    "    \n",
    "    # Wenn einmal in state 2, kann nicht mehr zurück in state 1\n",
    "    Q[:,:,:,0] = 0.0\n",
    "    \n",
    "    denominator = 1 + np.sum(np.exp(Q[..., 1:]), axis=3, keepdims=True)\n",
    "    Q = np.exp(Q)/denominator\n",
    "    \n",
    "    return Q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0021ec",
   "metadata": {},
   "source": [
    "#### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e6c3d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "197ba00b",
   "metadata": {},
   "source": [
    "##### Definition der Verteilungsfunktion F_1 von CEOM aals anzahl_kunden x 1 Array für jeden state und Monat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a1af4196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition der Erfolgswahrscheinlichkeit p_t als 1 x anzhal_kunden array \n",
    "def lambda_O_state_monat(alpha_o, beta_o, state, monat):\n",
    "    \n",
    "    state = state -1\n",
    "    \n",
    "    # Definitio von str_monat um auf den spaltennamen zugreifen zu können\n",
    "    str_monat = str(monat)\n",
    "    \n",
    "    # EM_iidt:Anzahl dversendeter Mails in Monat t an Kunde mit iid\n",
    "    EM_monat = df_HY[str_monat]\n",
    "    LO_monat = df_LO[str_monat]\n",
    "    \n",
    "    # Erhalten der Werte für die Verarbeitung in der Formel\n",
    "    array_lambda = np.exp(np.log(0.63)*EM_monat + alpha_o[state] + beta_o[0] * np.log(LO_monat))\n",
    "\n",
    "    return array_lambda\n",
    "\n",
    "# Array der Verteilungsfunktion der Öffungen O für Monat und state\n",
    "def F_O_state_monat(alpha_o, beta_o, state, monat):\n",
    "    \n",
    "    # Definitio von str_monat um auf den spaltennamen zugreifen zu können\n",
    "    str_monat = str(monat)\n",
    "    \n",
    "    # o_iidt: Anzahl geöffneter Mails in Monat t von allen Kunden\n",
    "    o_monat = df_NO_werte[str_monat]\n",
    "    \n",
    "    lambda_O_state_monat_berechnung = lambda_O_state_monat(alpha_o, beta_o, state, monat)\n",
    "    \n",
    "    array_F_O_berechnung = poisson.cdf(o_monat, lambda_O_state_monat_berechnung)\n",
    "         \n",
    "    return array_F_O_berechnung\n",
    "\n",
    "# Array der Verteilungsfunktion der Öffungen O -1 für Monat und state\n",
    "def F_O_state_monat_minusEins(alpha_o, beta_o, state, monat):\n",
    "    \n",
    "    # Definitio von str_monat um auf den spaltennamen zugreifen zu können\n",
    "    str_monat = str(monat)\n",
    "    \n",
    "    # o_iidt: Anzahl geöffneter Mails in Monat t von allen Kunden\n",
    "    o_monat = df_NO_minusEins[str_monat]\n",
    "    \n",
    "    lambda_O_state_monat_berechnung = lambda_O_state_monat(alpha_o, beta_o, state, monat)\n",
    "    \n",
    "    array_F_O_berechnung = poisson.cdf(o_monat, lambda_O_state_monat_berechnung)\n",
    "\n",
    "    return array_F_O_berechnung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b2c544",
   "metadata": {},
   "source": [
    "#### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59930dbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a762e9fd",
   "metadata": {},
   "source": [
    "##### Definition der Verteilungsfunktio F_2 von CPM als anzahl_kunden x 1 Array für jeden state und Monat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "69d53554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition der Wahrscheinlichkeit des Eintretens eines Erfolges im Einzelversuch phi als anzahl_iids x T df\n",
    "def phi_state_monat(delta_0, delta_1, state, monat):\n",
    "    \n",
    "    state = state -1\n",
    "    \n",
    "    # Definitio von str_monat um auf den spaltennamen zugreifen zu können\n",
    "    str_monat = str(monat)\n",
    "    \n",
    "    LY_monat = df_LY[str_monat]\n",
    "    array_phi = 1 / (1 + np.exp(delta_0[state] + delta_1[state] * np.log(LY_monat)))\n",
    "    \n",
    "    return array_phi\n",
    "\n",
    "# Definition der lambdaY als anzahl_iids x 1 array für monat und state\n",
    "def lambdaY_state_monat(alpha_p, beta_p_1, beta_p_2, state, monat):\n",
    "    \n",
    "    state = state -1\n",
    "    \n",
    "    # Definitio von str_monat um auf den spaltennamen zugreifen zu können\n",
    "    str_monat = str(monat)\n",
    "    EM_monat = df_HY[str_monat]\n",
    "    \n",
    "    array_lambdaY = np.exp(alpha_p[state] + beta_p_1[state] * EM_monat + beta_p_2[state] * np.square(EM_monat))\n",
    "    \n",
    "    return array_lambdaY\n",
    "\n",
    "# Array der Verteilungsfunktion der Käufe Y für Monat und state\n",
    "def F_Y_state_monat(delta_0, delta_1, alpha_p, beta_p_1, beta_p_2, state, monat):\n",
    "    \n",
    "    # Definitio von str_monat um auf den spaltennamen zugreifen zu können\n",
    "    str_monat = str(monat)\n",
    "    # y_monat ist das array mit der Anzahl an Käufen in monat str_monat\n",
    "    y_monat = df_trans_werte[str_monat]\n",
    "    # phi ist das 1 x anzahl_iids array mit phi für jeden kunden mit gegegebenem monat und state\n",
    "    phi = phi_state_monat(delta_0, delta_1, state, monat)\n",
    "    # lambdaY ist das 1 x anzahl_iids array mit lammbda für jeden kunden mit gegegebenem monat und state\n",
    "    lambdaY = lambdaY_state_monat(alpha_p, beta_p_1, beta_p_2, state, monat)\n",
    "    # pmf als 1x anzahl_iids array mit Nullen initieren\n",
    "    cdf = np.zeros_like(y_monat, dtype=float)\n",
    "    \n",
    "    if r[0] > 0:\n",
    "        for i in range(len(y_monat)):\n",
    "            for j in range(y_monat[i] + 1):\n",
    "                if j == 0:\n",
    "                    pmf = phi[i] + (1 - phi[i]) * (1 + lambdaY[i] / r[0])**(-r[0])\n",
    "                elif j > 0:\n",
    "                    numerator = math.gamma(j + r[0])\n",
    "                    denominator = math.factorial(j) * math.gamma(r[0])\n",
    "                    gamma_term = numerator / denominator\n",
    "                    pmf= (1 - phi[i]) * gamma_term * (1 + lambdaY[i] / r[0])**(-r[0]) * (1 + r[0] / lambdaY[i])**(-j)\n",
    "                cdf[i] += pmf\n",
    "    return cdf\n",
    "\n",
    "# Array der Verteilungsfunktion der Käufe Y-1 für Monat und state\n",
    "def F_Y_state_monat_minusEins(delta_0, delta_1, alpha_p, beta_p_1, beta_p_2, state, monat):\n",
    "    \n",
    "    # Definitio von str_monat um auf den spaltennamen zugreifen zu können\n",
    "    str_monat = str(monat)\n",
    "    # y_monat ist das array mit der Anzahl an Käufen in monat str_monat\n",
    "    y_monat = df_trans_werte[str_monat] -1\n",
    "    # phi ist das 1 x anzahl_iids array mit phi für jeden kunden mit gegegebenem monat und state\n",
    "    phi = phi_state_monat(delta_0, delta_1, state, monat)\n",
    "    # lambdaY ist das 1 x anzahl_iids array mit lammbda für jeden kunden mit gegegebenem monat und state\n",
    "    lambdaY = lambdaY_state_monat(alpha_p, beta_p_1, beta_p_2, state, monat)\n",
    "    # pmf als 1x anzahl_iids array mit Nullen initieren\n",
    "    cdf = np.zeros_like(y_monat, dtype=float)\n",
    "    \n",
    "    if r[0] > 0:\n",
    "        for i in range(len(y_monat)):\n",
    "            if y_monat[i] < 0:\n",
    "                cdf[i] = 0\n",
    "            else:\n",
    "                for j in range(y_monat[i] + 1):\n",
    "                    if j == 0:\n",
    "                        pmf = phi[i] + (1 - phi[i]) * (1 + lambdaY[i] / r[0])**(-r[0])\n",
    "                    elif j > 0:\n",
    "                        numerator = math.gamma((j) + r[0])\n",
    "                        denominator = math.factorial((j)) * math.gamma(r[0])\n",
    "                        gamma_term = numerator / denominator\n",
    "                        pmf= (1 - phi[i]) * gamma_term * (1 + lambdaY[i] / r[0])**(-r[0]) * (1 + r[0] / lambdaY[i])**(-(j))\n",
    "                cdf[i] += pmf\n",
    "    return cdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da44f57e",
   "metadata": {},
   "source": [
    "#### Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3cd732",
   "metadata": {},
   "source": [
    "##### Definition der Frank-copula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "93d54445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frank Copula, theta fehlt\n",
    "def Frank_copula(u_1, u_2, theta):\n",
    "    numerator = (np.exp(-theta[0]*u_1) - 1) * (np.exp(-theta[0]*u_2) - 1)\n",
    "    denominator = np.exp(-theta[0]) - 1\n",
    "    fraction = numerator / denominator\n",
    "    return (-1 / theta[0]) * np.log(1 + fraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ff64e7",
   "metadata": {},
   "source": [
    "##### Definition der Likelihoodfunktion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "847bd7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha_o, delta_0, delta_1, alpha_p, beta_p_1, beta_p_2 sind state dependent\n",
    "# beta_o, r sind state independent\n",
    "def likelihood_function(params):\n",
    "    \n",
    "    alpha_size = anzahl_states**2\n",
    "    gamma_size = anzahl_states**2 * 4\n",
    "\n",
    "    alpha = params[:alpha_size]\n",
    "    gamma = params[alpha_size:alpha_size+gamma_size]\n",
    "    alpha_o = params[alpha_size+gamma_size:alpha_size+gamma_size+anzahl_states]\n",
    "    beta_o = params[alpha_size+gamma_size+anzahl_states:alpha_size+gamma_size+anzahl_states+1]\n",
    "    delta_0 = params[alpha_size+gamma_size+anzahl_states+1:alpha_size+gamma_size+anzahl_states*2+1]\n",
    "    delta_1 = params[alpha_size+gamma_size+anzahl_states*2+1:alpha_size+gamma_size+anzahl_states*3+1]\n",
    "    alpha_p = params[alpha_size+gamma_size+anzahl_states*3+1:alpha_size+gamma_size+anzahl_states*4+1]\n",
    "    beta_p_1 = params[alpha_size+gamma_size+anzahl_states*4+1:alpha_size+gamma_size+anzahl_states*5+1]\n",
    "    beta_p_2 = params[alpha_size+gamma_size+anzahl_states*5+1:alpha_size+gamma_size+anzahl_states*6+1]\n",
    "    theta = params[alpha_size+gamma_size+anzahl_states*6+1:]\n",
    "\n",
    "\n",
    "    #alpha, gamma, alpha_o, beta_o, delta_0, delta_1, alpha_p, beta_p_1, beta_p_2, r, theta = params\n",
    "    ### Erstellung einer Liste H die alle H_it enthalten\n",
    "    H = np.zeros((anzahl_kunden, anzahl_monate, anzahl_states))\n",
    "                \n",
    "                \n",
    "    for monat in range(1,anzahl_monate+1):\n",
    "        for state in range(1, anzahl_states +1):\n",
    "            \n",
    "            # Berechnung von arrays für die Verteilungsfunktionen\n",
    "            F_O_state_monat_berechnung = F_O_state_monat(alpha_o, beta_o, state, monat)\n",
    "            \n",
    "            F_O_state_monat_berechnung_minusEins = F_O_state_monat_minusEins(alpha_o, beta_o, state, monat)\n",
    "            \n",
    "            F_Y_state_monat_berechnung = F_Y_state_monat(delta_0, delta_1, alpha_p, beta_p_1, beta_p_2, state, monat)\n",
    "            \n",
    "            F_Y_state_monat_berechnung_minusEins =\\\n",
    "                    F_Y_state_monat_minusEins(delta_0, delta_1, alpha_p, beta_p_1, beta_p_2, state, monat)\n",
    "            \n",
    "            # Berechnung der gemeinsamen Verteilungen\n",
    "            H_state_monat_berechnung =\\\n",
    "                            Frank_copula(F_O_state_monat_berechnung, F_Y_state_monat_berechnung, theta) -\\\n",
    "                            Frank_copula(F_O_state_monat_berechnung_minusEins, F_Y_state_monat_berechnung, theta) -\\\n",
    "                            Frank_copula(F_O_state_monat_berechnung, F_Y_state_monat_berechnung_minusEins, theta) +\\\n",
    "                            Frank_copula(F_O_state_monat_berechnung_minusEins, F_Y_state_monat_berechnung_minusEins, theta)\n",
    "            \n",
    "            # Speicherung der Werte in den leeren arrays\n",
    "            H[:, monat-1, state-1] = H_state_monat_berechnung\n",
    "\n",
    "    # Startverteilung ist (1, 0,..., 0)\n",
    "    startverteilung = np.zeros((1, anzahl_states))\n",
    "    startverteilung[0, 0] = 1\n",
    "    \n",
    "    # Transitionmatrix Q, liste von 3x3 Arrays, wobei für Monate 2, ..., 15 die Q_it angegeben werden und die Q_it fü die\n",
    "    # nächsten Kunden dahinter angehängt werden\n",
    "    Q = probability_Q_state_monat(alpha, gamma)\n",
    "    \n",
    "    eins_vektor = np.ones((anzahl_states, 1))\n",
    "    \n",
    "    likelihood = np.array([])\n",
    "    \n",
    "    for iid in range(anzahl_kunden):\n",
    "        result = startverteilung\n",
    "        result = np.matmul(result, np.diag(H[iid, 0]))\n",
    "        H_iid = np.eye(anzahl_states)\n",
    "        for monat in range(2, anzahl_monate+1):\n",
    "                H_iid_monat = np.matmul(np.diag(H[iid, monat-1]), Q[iid, monat-2])\n",
    "                H_iid = np.matmul(H_iid, H_iid_monat)\n",
    "        result = np.matmul(result, H_iid)\n",
    "        result = np.matmul(result, eins_vektor)\n",
    "        likelihood = np.concatenate((likelihood, result[0]))\n",
    "        \n",
    "    return abs(np.sum(np.log(likelihood)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2553a878",
   "metadata": {},
   "source": [
    "#### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "86e9ef60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values_quelle_alpha_o = [0]\n",
    "alpha_o = values_quelle_alpha_o * anzahl_states\n",
    "alpha_o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebd4d8b",
   "metadata": {},
   "source": [
    "# Berechnung der Likelihoodfunktion und Schätzung der Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42091ca4",
   "metadata": {},
   "source": [
    "### Dispersion Parameter r für die ZINBD Verteilun wurde vorhergeschätzt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b3bad52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = [1.29]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1899b5",
   "metadata": {},
   "source": [
    "### Definition der Startwerte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0128d379",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Parameter für Transitionmatrix\n",
    "values_quelle_alpha = [0, -2.647, -1.432, 0, 2.829, -3.815, 0, -2.398, 0.61]\n",
    "alpha = np.array(values_quelle_alpha)\n",
    "gamma = np.zeros((anzahl_states, anzahl_states, 4)).flatten()\n",
    "\n",
    "# Parameter für CEOM\n",
    "# values_quelle_alpha_o wurde aus einer vorherigen Optimierung übernommen\n",
    "values_quelle_alpha_o = [0]\n",
    "alpha_o = values_quelle_alpha_o * anzahl_states\n",
    "# values_quelle_beta_o wurdevorher nicht geschätzt\n",
    "values_quelle_beta_o = [0]\n",
    "beta_o = values_quelle_beta_o\n",
    "\n",
    "# Parameter für CPM\n",
    "# values_quelle_alpha_o wurde aus einer vorherigen Optimierung übernommen\n",
    "values_quelle_delta_0 = [np.log(1.29)]\n",
    "delta_0 = values_quelle_delta_0 * anzahl_states\n",
    "# values_quelle_delta_1 wurde nicht aus einer vorherigen Optimierung übernommen\n",
    "values_quelle_delta_1 = [0]\n",
    "delta_1 = values_quelle_delta_1 * anzahl_states\n",
    "# values_quelle_alpha_p wurde aus einer vorherigen Optimierung übernommen\n",
    "values_quelle_alpha_p = [np.log(0.779)]\n",
    "alpha_p = values_quelle_alpha_p * anzahl_states\n",
    "# beta_p_1 wurde nicht aus einer vorherigen Optimierung übernommen\n",
    "values_quelle_beta_p_1 = [0]\n",
    "beta_p_1 = values_quelle_beta_p_1 * anzahl_states\n",
    "# beta_p_2 wurde nicht aus einer vorherigen Optimierung übernommen\n",
    "values_quelle_beta_p_2 = [0]\n",
    "beta_p_2 = values_quelle_beta_p_2 * anzahl_states\n",
    "\n",
    "# Parameter für Frank_copula\n",
    "theta = np.array([0.324])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e92a28a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Startwerte\n",
    "x0 = np.concatenate((\n",
    "    alpha,\n",
    "    gamma,\n",
    "    alpha_o,\n",
    "    beta_o,\n",
    "    delta_0,\n",
    "    delta_1,\n",
    "    alpha_p,\n",
    "    beta_p_1,\n",
    "    beta_p_2,\n",
    "    theta))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e180c8",
   "metadata": {},
   "source": [
    "### Sonderfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "626d2941",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x0 = result.x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82a73b6",
   "metadata": {},
   "source": [
    "### Definition der Bounds und Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "21aee4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiere bounds\n",
    "#bounds = [(None, None)] * (len(x0) - 2) + [(1.1, 5)] + [(0.1, None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7d54274d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Für die Definition der constraint relevant\n",
    "alpha_size = anzahl_states**2\n",
    "gamma_size = anzahl_states**2 * 4\n",
    "# alpha_o = params[alpha_size+gamma_size:alpha_size+gamma_size+anzahl_states]\n",
    "constraint_matrix = np.zeros((2, len(x0)))\n",
    "# Positionen für alpha_o\n",
    "alpha_o_1_pos = alpha_size + gamma_size\n",
    "alpha_o_2_pos = alpha_size + gamma_size + 1\n",
    "alpha_o_3_pos = alpha_size + gamma_size + 2\n",
    "# -1 und 1 an den entsprechenden Positionen setzen\n",
    "constraint_matrix[0][alpha_o_1_pos] = -1\n",
    "constraint_matrix[0][alpha_o_2_pos] = 1\n",
    "constraint_matrix[1][alpha_o_2_pos] = -1\n",
    "constraint_matrix[1][alpha_o_3_pos] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "858d94bb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0., -1.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  1.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constraint_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "42242e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_constraint = LinearConstraint(constraint_matrix, [0, 0], [np.inf, np.inf])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3dc1b8",
   "metadata": {},
   "source": [
    "### Berechnung per minimize Funktion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "48ee675b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.95880863e-01 -3.59124400e+01  2.60329345e+02 -1.00722955e+00\n",
      "  6.59387043e+01 -6.26930093e+02  7.77765521e-01 -3.81809112e+02\n",
      "  4.22619581e+01  2.06501132e-01  4.54193632e-01  1.36149846e+00\n",
      "  1.61523183e-01 -1.64351156e+00  9.41530014e-01  6.66455195e-01\n",
      " -5.56561402e-01 -6.62948029e-01  2.73331771e-01 -2.00688420e-01\n",
      " -3.27223088e-01  3.29974292e-01 -3.32184316e-01  9.03486052e-02\n",
      "  2.29039068e-01 -7.45142595e-01 -4.69908577e-01  6.64073095e-01\n",
      " -8.42513154e-01 -4.32027146e-01  6.37971104e-01  5.56708319e-01\n",
      " -2.02488940e-02  5.01401989e-01 -3.74569508e-01 -1.03824332e-01\n",
      "  5.45743802e-01  6.90162228e-01 -1.05819761e+00 -1.35765315e+00\n",
      " -1.62542270e+00 -2.06105878e+00 -7.03188186e-01  7.56466752e-01\n",
      " -4.66463732e-01  3.63976520e-01  6.26360870e-01  1.20060261e+00\n",
      " -1.23388075e+00  1.72488333e+01  5.00884010e+01  2.77030690e+01\n",
      "  1.60098890e-02  4.82931457e-01  8.66934913e-01  3.82029460e-01\n",
      "  4.49416392e+01 -1.21758637e+00 -2.63664530e-01 -2.26657425e-01\n",
      " -7.09445291e-01 -2.71660466e-01  1.65419668e+00  2.02964651e-01\n",
      "  1.39717589e+00]\n"
     ]
    }
   ],
   "source": [
    "# Rufen Sie minimize() auf und übergeben Sie die zusätzlichen Parameter mit args=\n",
    "result = minimize(likelihood_function, x0, method = \"Nelder-Mead\") \n",
    "                  #constraints=linear_constraint)\n",
    "                  #args=(alpha, gamma, alpha_o, beta_o, delta_0, delta_1, alpha_p, beta_p_1, beta_p_2, r, theta), bounds=bounds)\n",
    "\n",
    "# Gib die geschätzten Parameter aus\n",
    "print(result.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4b0604b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likelihood für optimale Parameter:\n",
      "18338.470744301358\n"
     ]
    }
   ],
   "source": [
    "# Berechne die Likelihood für die optimalen Parameter\n",
    "likelihood = likelihood_function(result.x)\n",
    "print(\"Likelihood für optimale Parameter:\")\n",
    "print(likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "cb21a0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(result.success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e3c3d3f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " final_simplex: (array([[ 3.95880863e-01, -3.59124400e+01,  2.60329345e+02, ...,\n",
       "         1.65419668e+00,  2.02964651e-01,  1.39717589e+00],\n",
       "       [ 3.94306976e-01, -3.90519512e+01,  2.60083830e+02, ...,\n",
       "         1.64958301e+00,  1.94099050e-01,  1.50083721e+00],\n",
       "       [ 3.95804741e-01, -4.03192124e+01,  2.61364365e+02, ...,\n",
       "         1.65377256e+00,  1.95196703e-01,  1.52251184e+00],\n",
       "       ...,\n",
       "       [ 3.95647340e-01, -4.24448993e+01,  2.59700701e+02, ...,\n",
       "         1.63710388e+00,  1.89443821e-01,  1.55123550e+00],\n",
       "       [ 3.96723384e-01, -4.10408248e+01,  2.59543904e+02, ...,\n",
       "         1.64332712e+00,  1.91781990e-01,  1.55329846e+00],\n",
       "       [ 3.95868872e-01, -4.09672153e+01,  2.59873192e+02, ...,\n",
       "         1.65858177e+00,  1.96311142e-01,  1.63138819e+00]]), array([18338.4707443 , 18339.80927999, 18340.16873346, 18340.47471343,\n",
       "       18340.66566118, 18340.68899906, 18340.72547323, 18340.87664505,\n",
       "       18340.91719293, 18341.3382033 , 18341.40513936, 18341.50510293,\n",
       "       18341.54350093, 18341.57432228, 18341.58264482, 18341.76684046,\n",
       "       18341.82211573, 18341.83268991, 18341.86957223, 18341.91361539,\n",
       "       18342.29795725, 18342.41742218, 18342.51078925, 18342.58164568,\n",
       "       18342.6028758 , 18342.63846588, 18342.67089705, 18342.6964392 ,\n",
       "       18342.7078453 , 18342.77512385, 18343.05352543, 18343.06013767,\n",
       "       18343.10255482, 18343.15566172, 18343.17008805, 18343.1832432 ,\n",
       "       18343.22602848, 18343.35826194, 18343.4075973 , 18343.48737872,\n",
       "       18343.51624442, 18343.67117406, 18343.92193397, 18343.9565423 ,\n",
       "       18343.98324177, 18344.17816729, 18344.23181421, 18344.24639796,\n",
       "       18344.29025938, 18344.37398682, 18344.39000595, 18344.4969185 ,\n",
       "       18344.80278293, 18344.84657416, 18344.99338242, 18345.01018704,\n",
       "       18345.13802143, 18345.15544019, 18345.16481494, 18345.19797777,\n",
       "       18345.25189938, 18345.41372353, 18345.437372  , 18345.44159622,\n",
       "       18345.53885534, 18345.58111642]))\n",
       "           fun: 18338.470744301358\n",
       "       message: 'Maximum number of function evaluations has been exceeded.'\n",
       "          nfev: 13000\n",
       "           nit: 12152\n",
       "        status: 1\n",
       "       success: False\n",
       "             x: array([ 3.95880863e-01, -3.59124400e+01,  2.60329345e+02, -1.00722955e+00,\n",
       "        6.59387043e+01, -6.26930093e+02,  7.77765521e-01, -3.81809112e+02,\n",
       "        4.22619581e+01,  2.06501132e-01,  4.54193632e-01,  1.36149846e+00,\n",
       "        1.61523183e-01, -1.64351156e+00,  9.41530014e-01,  6.66455195e-01,\n",
       "       -5.56561402e-01, -6.62948029e-01,  2.73331771e-01, -2.00688420e-01,\n",
       "       -3.27223088e-01,  3.29974292e-01, -3.32184316e-01,  9.03486052e-02,\n",
       "        2.29039068e-01, -7.45142595e-01, -4.69908577e-01,  6.64073095e-01,\n",
       "       -8.42513154e-01, -4.32027146e-01,  6.37971104e-01,  5.56708319e-01,\n",
       "       -2.02488940e-02,  5.01401989e-01, -3.74569508e-01, -1.03824332e-01,\n",
       "        5.45743802e-01,  6.90162228e-01, -1.05819761e+00, -1.35765315e+00,\n",
       "       -1.62542270e+00, -2.06105878e+00, -7.03188186e-01,  7.56466752e-01,\n",
       "       -4.66463732e-01,  3.63976520e-01,  6.26360870e-01,  1.20060261e+00,\n",
       "       -1.23388075e+00,  1.72488333e+01,  5.00884010e+01,  2.77030690e+01,\n",
       "        1.60098890e-02,  4.82931457e-01,  8.66934913e-01,  3.82029460e-01,\n",
       "        4.49416392e+01, -1.21758637e+00, -2.63664530e-01, -2.26657425e-01,\n",
       "       -7.09445291e-01, -2.71660466e-01,  1.65419668e+00,  2.02964651e-01,\n",
       "        1.39717589e+00])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc6b0b2",
   "metadata": {},
   "source": [
    "# Ergebisse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c1328a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array_lambda = np.exp(np.log(0.63*EM_monat) + alpha_o[state] + beta_o[0] * np.log(LO_monat))\n",
      "array_lambda = array_lambda / 1 + array_lambda\n",
      "array_exp = np.exp(alpha_p[state] + beta_p_1[state] * EM_monat + beta_p_2[state] * np.square(EM_monat))\n",
      "Likelihood für optimale Parameter: 17812\n"
     ]
    }
   ],
   "source": [
    "# Ausgangssituation\n",
    "print(\"array_lambda = np.exp(np.log(0.63*EM_monat) + alpha_o[state] + beta_o[0] * np.log(LO_monat))\")\n",
    "print(\"array_lambda = array_lambda / 1 + array_lambda\")\n",
    "print(\"array_exp = np.exp(alpha_p[state] + beta_p_1[state] * EM_monat + beta_p_2[state] * np.square(EM_monat))\")\n",
    "print(\"Likelihood für optimale Parameter: 17812\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9c2e7da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array_lambda = np.exp(np.log(0.63*EM_monat) + alpha_o[state] + beta_o[0] * np.log(LO_monat))\n",
      "array_lambda = array_lambda\n",
      "array_exp = np.exp(alpha_p[state] + beta_p_1[state] * EM_monat + beta_p_2[state] * np.square(EM_monat))\n",
      "Likelihood für optimale Parameter: 17812\n"
     ]
    }
   ],
   "source": [
    "# Test ob array_lambda = array_lambda / 1 + array_lambda bessere oder schlechtere Ergebnisse liefert \n",
    "print(\"array_lambda = np.exp(np.log(0.63*EM_monat) + alpha_o[state] + beta_o[0] * np.log(LO_monat))\")\n",
    "print(\"array_lambda = array_lambda\")\n",
    "print(\"array_exp = np.exp(alpha_p[state] + beta_p_1[state] * EM_monat + beta_p_2[state] * np.square(EM_monat))\")\n",
    "print(\"Likelihood für optimale Parameter: 17812\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "57000de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array_lambda = np.exp(np.log(0.63*EM_monat) + alpha_o[state] + beta_o[0] * np.log(LO_monat))\n",
      "array_lambda = array_lambda\n",
      "array_exp = np.exp(alpha_p[state] + beta_p_1[state] * EM_monat)\n",
      "Likelihood für optimale Parameter: 17812\n"
     ]
    }
   ],
   "source": [
    "# Test kein quadratischer Einfluss des EM auf Käufe\n",
    "print(\"array_lambda = np.exp(np.log(0.63*EM_monat) + alpha_o[state] + beta_o[0] * np.log(LO_monat))\")\n",
    "print(\"array_lambda = array_lambda\")\n",
    "print(\"array_exp = np.exp(alpha_p[state] + beta_p_1[state] * EM_monat)\")\n",
    "print(\"Likelihood für optimale Parameter: 17812\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2fbf7a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array_lambda = np.exp(np.log(0.63*EM_monat) + alpha_o[state] + beta_o[0] * np.log(LO_monat))\n",
      "array_lambda = array_lambda\n",
      "array_exp = np.exp(alpha_p[state] + beta_p_1[state] * EM_monat + beta_p_2[state] * np.square(EM_monat))\n",
      "Likelihood für optimale Parameter: 17547\n"
     ]
    }
   ],
   "source": [
    "# Test, ob keine \"keine constraints\" zu besseren Ergebnissen führt\n",
    "print(\"array_lambda = np.exp(np.log(0.63*EM_monat) + alpha_o[state] + beta_o[0] * np.log(LO_monat))\")\n",
    "print(\"array_lambda = array_lambda\")\n",
    "print(\"array_exp = np.exp(alpha_p[state] + beta_p_1[state] * EM_monat + beta_p_2[state] * np.square(EM_monat))\")\n",
    "print(\"Likelihood für optimale Parameter: 17547\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8442ee3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "likelihood mit ZINBD: 14451\n"
     ]
    }
   ],
   "source": [
    "#Ob nach Anpassungen die schönere Schreibweise auch für die ZINBD Definition funktioeiert und dieselben Ergebnisse liefert\n",
    "print(\"likelihood mit ZINBD: 14451\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "02f9d767",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "likelihood mit ZINBD:\n",
      "array_lambda = np.exp(np.log(0.63*EM_monat) + alpha_o[state] + beta_o[0] * np.log(LO_monat))\n",
      "array_lambda = array_lambda\n",
      "array_exp = np.exp(alpha_p[state] + beta_p_1[state] * EM_monat + beta_p_2[state] * np.square(EM_monat))\n",
      "Likelihood für optimale Parameter: 14451\n",
      "Parameter:\n"
     ]
    }
   ],
   "source": [
    "# Test ob für Standardspezifikation\n",
    "print(\"likelihood mit ZINBD:\")\n",
    "print(\"array_lambda = np.exp(np.log(0.63*EM_monat) + alpha_o[state] + beta_o[0] * np.log(LO_monat))\")\n",
    "print(\"array_lambda = array_lambda\")\n",
    "print(\"array_exp = np.exp(alpha_p[state] + beta_p_1[state] * EM_monat + beta_p_2[state] * np.square(EM_monat))\")\n",
    "print(\"Likelihood für optimale Parameter: 14451\")\n",
    "print(\"Parameter:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "dddde613",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_param = [ 0.00000000e+00, -8.42013774e+01,  1.69986125e+01,  0.00000000e+00,\n",
    "       -1.25200153e+01, -1.53060979e+01,  0.00000000e+00, -4.01802666e+00,\n",
    "        3.14514828e+01,  0.00000000e+00, -3.40875207e+01, -2.82844507e-01,\n",
    "        0.00000000e+00, -1.16977610e+01, -4.21223535e+01,  0.00000000e+00,\n",
    "       -3.23512569e+01,  5.05520432e+00,  0.00000000e+00, -1.36423722e+00,\n",
    "       -1.19458664e+00,  0.00000000e+00,  1.05242438e+00, -1.51554184e+01,\n",
    "        0.00000000e+00,  1.02752609e+00,  8.49398978e-01,  0.00000000e+00,\n",
    "        7.18296331e+01,  4.41698548e-01,  0.00000000e+00,  1.58841432e+01,\n",
    "        1.58119714e+01,  0.00000000e+00,  1.02333573e+01, -1.84782829e+01,\n",
    "        0.00000000e+00, -1.06581824e+01, -4.26447692e-01,  0.00000000e+00,\n",
    "        2.48374764e+01,  2.47507462e+01,  0.00000000e+00, -1.02161982e+00,\n",
    "        4.57256224e+00,  2.68038255e-02, -9.78697275e-01,  2.34488631e-01,\n",
    "       -2.46871753e-01,  1.80545838e+01,  2.12346810e+01,  1.49348847e+01,\n",
    "        0.00000000e+00,  1.72348151e-01, -3.64387979e-01, -5.53773619e-01,\n",
    "       -2.76890669e+00, -1.66599130e+00,  4.94843823e-01,  8.64751297e-01,\n",
    "       -6.48676929e-02, -2.92112867e-01, -1.55380568e-01,  5.61001901e-02,\n",
    "        1.47689589e+00]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "31bc225a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "likelihood mit ZINBD:\n",
      "array_lambda = np.exp(np.log(0.63)*EM_monat + alpha_o[state] + beta_o[0] * np.log(LO_monat))\n",
      "array_lambda = array_lambda\n",
      "array_exp = np.exp(alpha_p[state] + beta_p_1[state] * EM_monat + beta_p_2[state] * np.square(EM_monat))\n",
      "Likelihood für optimale Parameter: 18522\n"
     ]
    }
   ],
   "source": [
    "# Test ob np.log(0.63)*EM_monat besser als np.log(0.63*EM_monat)läuft und evtl terminiert\n",
    "print(\"likelihood mit ZINBD:\")\n",
    "print(\"array_lambda = np.exp(np.log(0.63)*EM_monat + alpha_o[state] + beta_o[0] * np.log(LO_monat))\")\n",
    "print(\"array_lambda = array_lambda\")\n",
    "print(\"array_exp = np.exp(alpha_p[state] + beta_p_1[state] * EM_monat + beta_p_2[state] * np.square(EM_monat))\")\n",
    "print(\"Likelihood für optimale Parameter: 18522\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f80a56f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_param = [ 0.00000000e+00, -8.42324287e+01,  1.69437089e+01,  0.00000000e+00,\n",
    "       -1.51114259e+01, -1.27787560e+01,  0.00000000e+00, -4.66039409e+00,\n",
    "        3.23378060e+01,  0.00000000e+00, -3.42059247e+01, -3.03032101e-01,\n",
    "        0.00000000e+00, -1.16969644e+01, -4.21223535e+01,  0.00000000e+00,\n",
    "       -3.23512569e+01,  5.10330353e+00,  0.00000000e+00, -1.34546356e+00,\n",
    "       -1.45060842e+00,  0.00000000e+00,  1.05242438e+00, -1.51554184e+01,\n",
    "        0.00000000e+00,  6.50267936e-01,  1.11128688e+00,  0.00000000e+00,\n",
    "        7.18149941e+01,  5.07482709e-01,  0.00000000e+00,  1.65202863e+01,\n",
    "        1.50351002e+01,  0.00000000e+00,  9.40601150e+00, -1.66324994e+01,\n",
    "        0.00000000e+00, -1.05955017e+01, -1.72078495e-01,  0.00000000e+00,\n",
    "        2.62869932e+01,  2.28266666e+01,  0.00000000e+00, -1.69422693e+00,\n",
    "        7.29303793e+00,  4.87220599e-01,  7.01288616e-01,  1.24299189e+00,\n",
    "       -1.36993482e+00,  1.80247785e+01,  2.12346810e+01,  1.55971024e+01,\n",
    "        0.00000000e+00,  1.72348151e-01, -5.49982853e-01, -2.11311398e-01,\n",
    "       -3.31995657e+00, -1.50224012e+00,  2.04106841e-01,  1.71997448e+00,\n",
    "       -8.41039175e-02, -2.74031043e-01, -4.31434986e-01,  1.32125605e-02,\n",
    "        1.07630364e+00]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "91473699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "likelihood mit ZINBD:\n",
      "array_lambda = np.exp(np.log(0.63)*EM_monat + alpha_o[state] + beta_o[0] * np.log(LO_monat))\n",
      "array_lambda = array_lambda\n",
      "array_exp = np.exp(alpha_p[state] + beta_p_1[state] * EM_monat + beta_p_2[state] * np.square(EM_monat))\n",
      "Likelihood für optimale Parameter: 18522\n",
      "result.success: False\n"
     ]
    }
   ],
   "source": [
    "# Test ob np.log(0.63)*EM_monat besser als np.log(0.63*EM_monat)läuft und evtl terminiert\n",
    "print(\"likelihood mit ZINBD:\")\n",
    "print(\"array_lambda = np.exp(np.log(0.63)*EM_monat + alpha_o[state] + beta_o[0] * np.log(LO_monat))\")\n",
    "print(\"array_lambda = array_lambda\")\n",
    "print(\"array_exp = np.exp(alpha_p[state] + beta_p_1[state] * EM_monat + beta_p_2[state] * np.square(EM_monat))\")\n",
    "print(\"Likelihood für optimale Parameter: 18522\")\n",
    "print(\"result.success: False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3d1c854e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "likelihood mit ZINBD:\n",
      "array_lambda = np.exp(np.log(0.63)*EM_monat + alpha_o[state] + beta_o[0] * np.log(LO_monat))\n",
      "array_lambda = array_lambda\n",
      "array_exp = np.exp(alpha_p[state] + beta_p_1[state] * EM_monat + beta_p_2[state] * np.square(EM_monat))\n",
      "Likelihood für optimale Parameter: 18716\n"
     ]
    }
   ],
   "source": [
    "# Test ob Q[:,:,:,0] ungleich Null zu besseren Ergebnissen führt\n",
    "print(\"likelihood mit ZINBD:\")\n",
    "print(\"array_lambda = np.exp(np.log(0.63)*EM_monat + alpha_o[state] + beta_o[0] * np.log(LO_monat))\")\n",
    "print(\"array_lambda = array_lambda\")\n",
    "print(\"array_exp = np.exp(alpha_p[state] + beta_p_1[state] * EM_monat + beta_p_2[state] * np.square(EM_monat))\")\n",
    "print(\"Likelihood für optimale Parameter: 18716\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "967701cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_param_positiveQ_state1_Nelder = [-7.44841087e-01, -8.85139802e+02, -2.40481934e+02, -2.05213086e+00,\n",
    "       -5.60706087e+02, -5.35441302e+02, -9.63275246e-03, -4.27150076e+02,\n",
    "       -1.92413334e+01,  1.87679188e+00,  1.58999244e-01, -9.03253128e-02,\n",
    "       -3.28630690e-01, -2.43215232e-01, -1.37190579e-01,  3.42037204e-01,\n",
    "        2.51357509e-01,  2.06682854e-01, -4.73934832e-01, -2.71680222e-01,\n",
    "        1.60689390e-01, -1.72473497e-01, -2.60376329e-01,  2.51404015e-01,\n",
    "       -1.00917729e-02, -7.52990475e-01,  2.61244903e-02,  7.95823527e-01,\n",
    "       -5.31101017e-02, -2.62763614e-01,  8.73203616e-01, -7.32946413e-01,\n",
    "       -3.99863957e-01,  5.41473133e-01,  1.89988509e+00, -7.65683186e-01,\n",
    "        5.79608497e-01,  1.28236010e-01,  9.41770971e-01, -8.84228191e-01,\n",
    "       -7.05129175e-01, -2.51729254e+00, -1.31076750e+00,  1.76696263e-01,\n",
    "        3.34715279e-01,  1.11964744e+00,  3.44350612e-01,  3.11862570e+00,\n",
    "       -1.35299604e+00,  9.91086034e+01,  5.99497355e+00, -4.56900519e+01,\n",
    "       -4.73360515e-01, -7.11949781e-01,  6.54292220e-02, -1.26160660e+00,\n",
    "        7.29158556e+01, -3.38290584e+01, -2.22817443e-01,  8.27814530e-02,\n",
    "       -4.07211009e-01,  5.30692948e-02, -8.46733418e-01, -5.21951998e-01,\n",
    "        4.65391969e-01]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae4c0ff",
   "metadata": {},
   "source": [
    "### Aktueller Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b5c9d65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "likelihood mit ZINBD:\n",
      "array_lambda = np.exp(np.log(0.63)*EM_monat + alpha_o[state] + beta_o[0] * np.log(LO_monat))\n",
      "array_lambda = array_lambda\n",
      "array_exp = np.exp(alpha_p[state] + beta_p_1[state] * EM_monat + beta_p_2[state] * np.square(EM_monat))\n",
      "Likelihood für optimale Parameter: 18716\n",
      "18338.470744301358\n"
     ]
    }
   ],
   "source": [
    "# Test ob Q[:,:,:,0] ungleich Null, Nelder-Mead, vorherige Datenbereinigung zu besseren Ergebnissen führt\n",
    "print(\"likelihood mit ZINBD:\")\n",
    "print(\"array_lambda = np.exp(np.log(0.63)*EM_monat + alpha_o[state] + beta_o[0] * np.log(LO_monat))\")\n",
    "print(\"array_lambda = array_lambda\")\n",
    "print(\"array_exp = np.exp(alpha_p[state] + beta_p_1[state] * EM_monat + beta_p_2[state] * np.square(EM_monat))\")\n",
    "print(\"Likelihood für optimale Parameter: 18716\")\n",
    "print(likelihood)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633b62fd",
   "metadata": {},
   "source": [
    "# Code Graveyard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1ad14f",
   "metadata": {},
   "source": [
    "Vorherige Definition der Verteilungsfunktion von O_it über Schleifen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18d0a3c",
   "metadata": {},
   "source": [
    "##### Definition der Erfolgswahrscheinlichkeit p_it als 1 x anzhal_states array \n",
    "def p_alt(iid, t, alpha_o, beta_o):\n",
    "    LO_iddt = df_LO.loc[df_LO['iid'] == iid, t].values[0]\n",
    "    p = exp(alpha_o + beta_o * np.log(LO_iddt)) / (1 + exp(alpha + beta * log(LO_iddt)))\n",
    "    return p\n",
    "\n",
    "#Wahrscheinlichkeiten werden in Array von Arrays zurückgegeben\n",
    "def F_O_iidt_alt(alpha_o, beta_o):\n",
    "    # P_O_iidt_speicher als Zwischenspeicher\n",
    "    P_O_iidt_speicher_gesamt = []\n",
    "    \n",
    "    for iid in trans[\"iid\"]:\n",
    "        # P_O_iidt_speicher als Zwischenspeicher für jede iid\n",
    "        P_O_iidt_speicher_jede_iid = []\n",
    "        \n",
    "        for t in range(1, 16):\n",
    "            # Defintion der Erfolgswahrscheinlichkeit p_it mit alpha_o_gegeben_s und beta_o als Paramater\n",
    "            # erfolgs_p = p(iid, t, alpha_o, beta_o)\n",
    "            \n",
    "            # EM_iidt:Anzahl dversendeter Mails in Monat t an Kunde mit iid\n",
    "            EM_iidt = df_HY.loc[df_HY['iid'] == iid, t].values[0]\n",
    "            \n",
    "            # o_iidt: Anzahl geöffneter Mails von Kunde iid in Monat t\n",
    "            o_iidt = df_NO.loc[df_NO['iid'] == iid, t].values[0]\n",
    "            \n",
    "            # Wahrscheinlichkeiten der Binomialverteilung für jeden Zustand\n",
    "            P_O_it = binom.cdf(o_iidt, EM_iidt, p(iid, t, alpha_o, beta_o))\n",
    "        \n",
    "            # Speichern der Wahrscheinlichkeiten im Zwischenspeicher\n",
    "            P_O_iidt_speicher_jede_iid = P_O_iidt_speicher_jede_iid.extend(P_O_it)\n",
    "\n",
    "        # In einer neuen Zeile für jede iid in dem Zwischenspeicher abspeichern\n",
    "        P_O_iidt_speicher_gesamt = np.vstack([P_O_iidt_speicher_gesamt, P_O_iidt_speicher])\n",
    "        \n",
    "    return P_O_iidt_speicher_gesamt\n",
    "\n",
    "\n",
    "##### Tests mit Diagonalmatrizen\n",
    "            # Erstellen des Namens der Diagonalmatrix\n",
    "            # name = f\"diagonal_matrix_PO_{iid}_{t}\"\n",
    "        \n",
    "            # Erstellen der Diagonalmatrix mit den Wahrscheinlichkeiten und dem Namen\n",
    "            # diagonal_matrix = np.diag(probabilities)\n",
    "            # diagonal_matrix.name = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae328397",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e376845",
   "metadata": {},
   "source": [
    "# Code wo veruscht wurde die arrays mit namen zu identifizieren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e50168",
   "metadata": {},
   "source": [
    "#### Definition der Erfolgswahrscheinlichkeit p_t als 1 x anzhal_kunden array \n",
    "def Q_v_state_t_minusEins_state_t_monat(alpha, gamma, state_t_minusEins, state_t, monat):\n",
    "    \n",
    "    state_t_minusEins = state_t_minusEins -1\n",
    "    state_t = state_t -1\n",
    "    str_monat = str(monat)\n",
    "    \n",
    "    # Definition der X_t_minusEins\n",
    "    # verwendete Parameter\n",
    "    EM_monat_minusEins = df_HY[str_monat]\n",
    "    Y_monat_minusEins = df_trans_werte[str_monat]\n",
    "    O_monat_minusEins = df_NO[str_monat]\n",
    "    # Definition\n",
    "    X_t_minusEins = [int(O_monat_minusEins > 0), int(Y_monat_minusEins > 0),\\\n",
    "                     EM_monat_minusEins, np.square(EM_monat_minusEins)]\n",
    "    \n",
    "    array_v = alpha[12*state_t_minusEins + 4*state + state] + gamma[12*state_t_minusEins + 4*state + state] * X_t_minusEins\n",
    "\n",
    "    return array_v\n",
    "\n",
    "##### Definition der Transitionmatrix\n",
    "def probability_Q_state_monat(alpha, gamma):\n",
    "    \n",
    "    ### Erstellung leerer anzahl_states x anzahl_states arrays für jeden Kunden und jeden Monat\n",
    "    Q = []\n",
    "    for iid in df_trans_werte[\"iid\"]:\n",
    "        for monat in range(2,16):\n",
    "                empty_array = np.zeros((anzahl_states, anzahl_states))\n",
    "                Q.append(empty_array)\n",
    "                \n",
    "                #name = f\"matrix_Q_{iid}_{monat}\"\n",
    "                #empty_array.name = name\n",
    "                \n",
    "    for monat in range(2,16):\n",
    "        \n",
    "        for state_t_minusEins in range(1, anzahl_states +1):\n",
    "            \n",
    "            # Erste Spalte besteht aus Nullen, da eine Trasition zurück in state 1 nicht möglich ist\n",
    "            for state in range(2, anzahl_states +1):\n",
    "                \n",
    "                q_array_iid_monat_state = Q_v_state_t_minusEins_state_t_monat(alpha, gamma, state_t_minusEins, state_t, monat)\n",
    "                #name = f\"Q_{iid}_{monat}\"\n",
    "\n",
    "                # Überführen zu df und Hinzufügen einer iid Spalte zur Identifikation\n",
    "                q_array_iid_monat_state = pd.DataFrame(q_array_iid_monat_state)\n",
    "                q_array_iid_monat_state[\"iid\"] = df_trans_werte[\"iid\"]\n",
    "\n",
    "                # Speicherung der Werte in den leeren arrays\n",
    "                for index in q_array_iid_monat_state:\n",
    "                    #name = f\"matrix_Q_{iid}_{monat}\"\n",
    "                    #array_iid_monat = Q[name]\n",
    "                    \n",
    "                    #Neue Definition ohne die Verwedung von Namen\n",
    "                    Q[index][state_t_minusEins-1, state-1] =\\\n",
    "                                    q_array_iid_monat_state[index]\n",
    "                   \n",
    "                    #array_iid_monat[state_t_minusEins-1, state-1] =\\\n",
    "                                    #q_array_iid_monat_state[q_array_iid_monat_state[\"iid\"] == \"iid\"]\n",
    "    \n",
    "    return Q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3224fdde",
   "metadata": {},
   "source": [
    "#### alpha_o, delta_0, delta_1, alpha_p, beta_p_1, beta_p_2 sind state dependent\n",
    "#### beta_o, r sind state independent\n",
    "def likelihood_function(alpha, gamma, alpha_o, beta_o, delta_0, delta_1,\\\n",
    "                        alpha_p, beta_p_1, beta_p_2, r, theta):\n",
    "    \n",
    "    ### Erstellung einer Liste H die alle H_it enthalten\n",
    "    H = []\n",
    "    \n",
    "    ### Erstellung leerer 1xanzahl_states arrays für jeden Kunden und jeden Monat\n",
    "    for iid in df_trans_werte[\"iid\"]:\n",
    "        for monat in range(1,16):\n",
    "                empty_array = np.zeros((1, anzahl_states))\n",
    "                H.append(empty_array)\n",
    "                \n",
    "                name = f\"diagonal_matrix_H_{iid}_{monat}\"\n",
    "                empty_array.name = name\n",
    "                \n",
    "    for monat in range(1,16):\n",
    "        for state in range(1, anzahl_states +1):\n",
    "            \n",
    "            # Berechnung von arrays für die Verteilungsfunktionen\n",
    "            F_O_state_monat_berechnung = F_O_state_monat(alpha_o, beta_o, state, monat)\n",
    "            \n",
    "            F_O_state_monat_berechnung_minusEins = F_O_state_monat_minusEins(alpha_o, beta_o, state, monat)\n",
    "            \n",
    "            F_Y_state_monat_berechnung =\\\n",
    "                            F_Y_state_monat(delta_0, delta_1, alpha_p, beta_p_1, beta_p_2, state, monat, r)\n",
    "            \n",
    "            F_Y_state_monat_berechnung_minusEins =\\\n",
    "                            F_Y_state_monat_minusEins(delta_0, delta_1, alpha_p, beta_p_1, beta_p_2, state, monat, r)\n",
    "            \n",
    "            # Berechnung der gemeinsamen Verteilungen\n",
    "            H_state_monat_berechnung =\\\n",
    "                            Frank_Copula(F_O_state_monat_berechnung, F_Y_state_monat_berechnung, theta) -\\\n",
    "                            Frank_Copula(F_O_state_monat_berechnung_minusEins, F_Y_state_monat_berechnung, theta) -\\\n",
    "                            Frank_Copula(F_O_state_monat_berechnung, F_Y_state_monat_berechnung_minusEins, theta) +\\\n",
    "                            Frank_Copula(F_O_state_monat_berechnung_minusEins, F_Y_state_monat_berechnung_minusEins, theta)\n",
    "            \n",
    "            # Überführen zu df und Hinzufügen einer iid Spalte zur Identifikation\n",
    "            H_state_monat_berechnung = pd.DataFrame(H_state_monat_berechnung)\n",
    "            H_state_monat_berechnung[\"iid\"] = df_trans_werte[\"iid\"]\n",
    "            \n",
    "            # Speicherung der Werte in den leeren arrays\n",
    "            for iid in H_state_monat_berechnung[\"iid\"]:\n",
    "                name = f\"diagonal_matrix_H_{iid}_{monat}\"\n",
    "                H[name][state-1] = H_state_monat_berechnung[H_state_monat_berechnung[\"iid\"] == \"iid\"]\n",
    "                \n",
    "    # Überführen der Arrays in H in Diagonalmatrizen\n",
    "    for array in H:\n",
    "        H[array] = np.diag(H[array])\n",
    "        \n",
    "    # Berechnung der Likelihood Function\n",
    "    likelihood = 1\n",
    "    \n",
    "    # Startverteilung ist (1, 0,..., 0)\n",
    "    startverteilung = np.zeros((1, anzahl_states))\n",
    "    startverteilung[0, 0] = 1\n",
    "    \n",
    "    # Transitionmatrix Q\n",
    "    Q = probability_Q_state_monat(alpha, gamma)\n",
    "    \n",
    "    Q_iid_prod = []\n",
    "    for iid in df_trans_werte[\"iid\"]:\n",
    "        Q_iid = np.dot(startverteilung, H[f\"diagonal_matrix_H_{iid}_1\"])\n",
    "\n",
    "        for monat in range(2,16):\n",
    "            name = f\"diagonal_matrix_H_{iid}_{monat}\"\n",
    "            name_Q = f\"matrix_Q_{iid}_{monat}\"\n",
    "            H_iid_monat = np.dot(H[name], Q[name_Q])\n",
    "            H_iid = np.dot(H_iid, H_iid_monat)\n",
    "            \n",
    "        Q_iid_prod.append(np.dot(Q_iid, H_iid))\n",
    "        \n",
    "    return np.prod(Q_iid_prod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1dfe91",
   "metadata": {},
   "source": [
    "# ZINBD Verteilungsfunktion mit Model modelliert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11a5b26",
   "metadata": {},
   "source": [
    "#### Definition der Wahrscheinlichkeit des Eintretens eines Erfolges im Einzelversuch phi als anzahl_iids x T df\n",
    "def phi_state_monat(delta_0, delta_1, state, monat):\n",
    "    \n",
    "    state = state -1\n",
    "    \n",
    "    # Definitio von str_monat um auf den spaltennamen zugreifen zu können\n",
    "    str_monat = str(monat)\n",
    "    \n",
    "    LY_monat = df_LY[str_monat]\n",
    "    array_phi = 1 / (1 + np.exp(delta_0[state] + delta_1[state] * np.log(LY_monat)))\n",
    "    \n",
    "    return array_phi\n",
    "\n",
    "#### Definition der lambdaY als anzahl_iids x 1 array für monat und state\n",
    "def lambdaY_state_monat(alpha_p, beta_p_1, beta_p_2, state, monat):\n",
    "    \n",
    "    state = state -1\n",
    "    \n",
    "    # Definitio von str_monat um auf den spaltennamen zugreifen zu können\n",
    "    str_monat = str(monat)\n",
    "    EM_monat = df_HY[str_monat]\n",
    "    \n",
    "    array_lambdaY = np.exp(alpha_p[state] + beta_p_1[state] * EM_monat + beta_p_2[state] * np.square(EM_monat))\n",
    "    \n",
    "    return array_lambdaY\n",
    "\n",
    "#### Array der Verteilungsfunktion der Käufe Y für Monat und state\n",
    "def F_Y_state_monat(delta_0, delta_1, alpha_p, beta_p_1, beta_p_2, state, monat, r):\n",
    "    \n",
    "    # Definitio von str_monat um auf den spaltennamen zugreifen zu können\n",
    "    str_monat = str(monat)\n",
    "    \n",
    "    # Erstellen Sie ein Zero-Inflated Negative Binomial Modell\n",
    "    zinb_model = ZeroInflatedNegativeBinomialP(endog=None, exog=None, exposure=None, offset=None, missing='none')\n",
    "\n",
    "    # Setzen Sie die offenen Parameter als Modellparameter\n",
    "    zinb_model.update({'params': [1- phi_state_monat(delta_0, delta_1, state, monat),\\\n",
    "                                  lambdaY_state_monat(alpha_p, beta_p_1, beta_p_2, state, monat),\\\n",
    "                                  r]})\n",
    "    \n",
    "    # y_iid ist das DataFrame mit der Anzahl an Käufen\n",
    "    y_monat = df_trans_werte[str_monat]\n",
    "    \n",
    "    # Verteilungsfunktion der ZINBD für jeden Zustand state\n",
    "    F_Y_it = zinb_model.cdf(y_monat)\n",
    "       \n",
    "    return F_Y_it\n",
    "\n",
    "#### Array der Verteilungsfunktion der Käufe Y-1 für Monat und state\n",
    "def F_Y_state_monat_minusEins(delta_0, delta_1, alpha_p, beta_p_1, beta_p_2, state, monat, r):\n",
    "    \n",
    "    # Berechnung der Werte minus Eins für spätere Berechnung der gemeinsamen Verteilung via Frank-Copula\n",
    "    df_trans_werte_minusEins = df_trans_werte.loc[:, df_NO_werte.columns != 'iid'] -1\n",
    "    \n",
    "    # Definitio von str_monat um auf den spaltennamen zugreifen zu können\n",
    "    str_monat = str(monat)\n",
    "    \n",
    "    # Erstellen Sie ein Zero-Inflated Negative Binomial Modell\n",
    "    zinb_model = ZeroInflatedNegativeBinomialP(endog=None, exog=None, exposure=None, offset=None, missing='none')\n",
    "\n",
    "    # Setzen Sie die offenen Parameter als Modellparameter\n",
    "    zinb_model.update({'params': [1- phi_state_monat(delta_0, delta_1, state, monat),\\\n",
    "                                  lambdaY_state_monat(alpha_p, beta_p_1, beta_p_2, state, monat),\\\n",
    "                                  r]})\n",
    "    \n",
    "    # y_iid ist das DataFrame mit der Anzahl an Käufen\n",
    "    y_monat = df_trans_werte_minusEins[str_monat]\n",
    "    \n",
    "    # Verteilungsfunktion der ZINBD für jeden Zustand state\n",
    "    F_Y_it = zinb_model.cdf(y_monat)\n",
    "       \n",
    "    return F_Y_it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e632841e",
   "metadata": {},
   "source": [
    "# CEOM als BD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2468e1",
   "metadata": {},
   "source": [
    "#### Definition der Erfolgswahrscheinlichkeit p_t als 1 x anzhal_kunden array \n",
    "def probability_O_state_monat(alpha_o, beta_o, state, monat):\n",
    "    \n",
    "    state = state -1\n",
    "    \n",
    "    # Definitio von str_monat um auf den spaltennamen zugreifen zu können\n",
    "    str_monat = str(monat)\n",
    "    \n",
    "    # Erhalten der Werte für die Verarbeitung in der Formel\n",
    "    LO_monat = df_LO[str_monat]\n",
    "    array_p = np.exp(alpha_o[state] + beta_o[0] * np.log(LO_monat)) / (1 + np.exp(alpha_o[state] + beta_o[0] * np.log(LO_monat)))\n",
    "\n",
    "    return array_p\n",
    "\n",
    "#### Array der Verteilungsfunktion der Öffungen O für Monat und state\n",
    "def F_O_state_monat(alpha_o, beta_o, state, monat):\n",
    "    \n",
    "    # Definitio von str_monat um auf den spaltennamen zugreifen zu können\n",
    "    str_monat = str(monat)\n",
    "    \n",
    "    # o_iidt: Anzahl geöffneter Mails in Monat t von allen Kunden\n",
    "    o_monat = df_NO_werte[str_monat]\n",
    "    \n",
    "    # EM_iidt:Anzahl dversendeter Mails in Monat t an Kunde mit iid\n",
    "    EM_monat = df_HY[str_monat]\n",
    "    \n",
    "    probs = probability_O_state_monat(alpha_o, beta_o, state, monat)\n",
    "    array_F_O_berechnung = binom.cdf(o_monat, EM_monat, probs)\n",
    "         \n",
    "    return array_F_O_berechnung\n",
    "\n",
    "#### Array der Verteilungsfunktion der Öffungen O -1 für Monat und state\n",
    "def F_O_state_monat_minusEins(alpha_o, beta_o, state, monat):\n",
    "    \n",
    "    # Definitio von str_monat um auf den spaltennamen zugreifen zu können\n",
    "    str_monat = str(monat)\n",
    "    \n",
    "    # o_iidt: Anzahl geöffneter Mails in Monat t von allen Kunden\n",
    "    o_monat = df_NO_minusEins[str_monat]\n",
    "    \n",
    "    # EM_iidt:Anzahl dversendeter Mails in Monat t an Kunde mit iid\n",
    "    EM_monat = df_HY[str_monat]\n",
    "    \n",
    "    probs = probability_O_state_monat(alpha_o, beta_o, state, monat)\n",
    "    array_F_O_berechnung = binom.cdf(o_monat, EM_monat, probs)\n",
    "\n",
    "    return array_F_O_berechnung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dec94b",
   "metadata": {},
   "source": [
    "#### Umständliche Defiitio Matrixmultiplikation\n",
    "    Q_iid_prod = np.array([1])\n",
    "    for j in range(len(df_trans_werte)):\n",
    "        Q_iid = np.dot(startverteilung, H[15 * j])\n",
    "        H_iid = np.eye(anzahl_states)\n",
    "        for monat in range(2,16):\n",
    "            H_iid_monat = np.dot(H[j * 15 + (monat-1)], Q[j * 14 + (monat-2)])\n",
    "            H_iid = np.dot(H_iid, H_iid_monat)\n",
    "            \n",
    "        Q_iid_prod.append(np.dot(Q_iid, H_iid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248a548f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
