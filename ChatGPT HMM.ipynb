{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a13d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Daten in ein Pandas-Dataframe laden\n",
    "data = pd.read_csv('sales_data.csv')\n",
    "\n",
    "# Aufteilen in Input-Features (Öffnungen) und Output-Features (Käufe)\n",
    "X = data[['Öffnungen']]\n",
    "y = data[['Käufe']]\n",
    "\n",
    "# Aufteilen in Trainings- und Testdaten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd0833f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(params, observations):\n",
    "    \"\"\"\n",
    "    Calculate the log likelihood of the HMM model given the parameters and observations.\n",
    "    \"\"\"\n",
    "    # Unpack the parameters\n",
    "    alpha, beta, gamma, delta, sigma_alpha, sigma_beta, rho, mu, sigma_rho, sigma_mu = params\n",
    "\n",
    "    # Initialize variables\n",
    "    log_likelihood = 0\n",
    "    state_probs = initial_state_probs(alpha, beta, gamma, delta, sigma_alpha, sigma_beta, rho, mu, sigma_rho, sigma_mu)\n",
    "\n",
    "    # Loop over the observations\n",
    "    for t in range(len(observations)):\n",
    "        obs = observations[t]\n",
    "        if t == 0:\n",
    "            log_likelihood += np.log(state_probs[obs[0]][obs[1]])\n",
    "        else:\n",
    "            log_likelihood += np.log(forward_step(obs, state_probs))\n",
    "        state_probs = backward_step(obs, state_probs)\n",
    "\n",
    "    return log_likelihood\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e40b166",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# Initial parameter values\n",
    "alpha = np.zeros((2, 2))\n",
    "beta = np.zeros((2, 2))\n",
    "gamma = np.zeros((2, 2))\n",
    "delta = np.zeros((2, 2))\n",
    "sigma_alpha = 1.0\n",
    "sigma_beta = 1.0\n",
    "rho = 0.5\n",
    "mu = np.zeros(2)\n",
    "sigma_rho = 1.0\n",
    "sigma_mu = 1.0\n",
    "\n",
    "params = [alpha, beta, gamma, delta, sigma_alpha, sigma_beta, rho, mu, sigma_rho, sigma_mu]\n",
    "\n",
    "# Perform Maximum Likelihood Estimation to fit the model\n",
    "result = minimize(lambda x: -log_likelihood(x, observations), params, method='L-BFGS-B')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430948aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the estimated parameters\n",
    "est_params = result.x\n",
    "alpha, beta, gamma, delta, sigma_alpha, sigma_beta, rho,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5547ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import gammaln\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def neg_log_likelihood(params, data):\n",
    "    \"\"\"\n",
    "    Function to compute the negative log-likelihood of the model.\n",
    "    \n",
    "    Parameters:\n",
    "    params (list): List of model parameters to be estimated.\n",
    "    data (tuple): Tuple containing the observed data.\n",
    "    \n",
    "    Returns:\n",
    "    neg_log_likelihood (float): The negative log-likelihood of the model.\n",
    "    \"\"\"\n",
    "    # Extract model parameters from params\n",
    "    alpha, beta, sigma_alpha, sigma_beta, delta, sigma_delta, r, gamma, sigma_gamma, pi = params\n",
    "    \n",
    "    # Extract observed data\n",
    "    o, y, em, lo, ly = data\n",
    "    \n",
    "    # Set up initial values\n",
    "    N = len(o)\n",
    "    log_likelihood = 0\n",
    "    \n",
    "    # Loop over all customers and time periods\n",
    "    for i in range(N):\n",
    "        for t in range(1, len(o[i])):\n",
    "            \n",
    "            # Calculate transition probability\n",
    "            v = alpha + gamma*em[i][t-1] + beta*np.log(lo[i][t-1])\n",
    "            e = np.random.gumbel(0, 1)\n",
    "            u = v + e\n",
    "            q = np.exp(u) / (1 + np.sum(np.exp(alpha + gamma*em[i][t-1] + beta*np.log(lo[i][t-1]))))\n",
    "            \n",
    "            # Calculate observation probabilities for opening and purchase\n",
    "            phi = 1 / (1 + np.exp(delta[0] + delta[1]*np.log(ly[i][t])))\n",
    "            lam = np.exp(gamma*em[i][t] + beta[0]*em[i][t]**2 + beta[1]*em[i][t] + alpha[1])\n",
    "            p_open = ((em[i][t]**o[i][t]) / gammaln(o[i][t]+1)) * (lam**o[i][t]) * np.exp(-lam) \n",
    "            p_buy = phi*(1-np.exp(-lam/r)) + (1-phi)*np.exp(-lam/r)*(1+ly[i][t]/r)**(-r)*(1+1/(ly[i][t]+1))\n",
    "            \n",
    "            # Calculate correlation\n",
    "            f1 = o[i][t]\n",
    "            f2 = y[i][t]\n",
    "            f1_1 = o[i][t-1]\n",
    "            f2_1 = y[i][t-1]\n",
    "            corr = c(f1, f2, pi) - c(f1_1, f2, pi) - c(f1, f2_1, pi) + c(f1_1, f2_1, pi)\n",
    "            \n",
    "            # Update log-likelihood\n",
    "            log_likelihood += np.log(q) + np.log(p_open) + np.log(p_buy) + corr\n",
    "    \n",
    "    # Return negative log-likelihood\n",
    "    return -log_likelihood\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f5185f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zustandsverteilung zum Zeitpunkt t=0\n",
    "startprob = np.array([0.5, 0.5])\n",
    "\n",
    "# Übergangsmatrix\n",
    "transmat = np.array([[0.7, 0.3],\n",
    "                     [0.3, 0.7]])\n",
    "\n",
    "# Emissionswahrscheinlichkeiten\n",
    "means = np.array([[0.0, 0.5], \n",
    "                  [1.0, 0.5]])\n",
    "\n",
    "covars = np.tile(np.identity(2), (2,1,1))\n",
    "\n",
    "model = hmm.GaussianHMM(n_components=2, covariance_type=\"full\")\n",
    "model.startprob_ = startprob\n",
    "model.transmat_ = transmat\n",
    "model.means_ = means\n",
    "model.covars_ = covars\n",
    "\n",
    "# Vorhersage für die nächsten 5 Schritte\n",
    "predicted_states, _ = model.predict(X, n_steps=5)\n",
    "\n",
    "print(predicted_states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa31b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorhersagen auf Testdaten\n",
    "test_preds = model.predict(test_data)\n",
    "test_open_preds = test_preds[:, 0]\n",
    "test_purchase_preds = test_preds[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff31ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mittlere absolute Abweichung für Öffnungen\n",
    "test_open_mae = np.mean(np.abs(test_open_preds - test_data[:, 0]))\n",
    "\n",
    "# Mittlere absolute Abweichung für Käufe\n",
    "test_purchase_mae = np.mean(np.abs(test_purchase_preds - test_data[:, 1]))\n",
    "\n",
    "print(f'Test MAE für Öffnungen: {test_open_mae:.4f}')\n",
    "print(f'Test MAE für Käufe: {test_purchase_mae:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525d1ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot für Öffnungen\n",
    "plt.scatter(test_data[:, 0], test_open_preds, alpha=0.5)\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.xlabel('Tatsächliche Öffnungen')\n",
    "plt.ylabel('Vorhergesagte Öffnungen')\n",
    "plt.title('Vorhersagegenauigkeit für Öffnungen')\n",
    "plt.show()\n",
    "\n",
    "# Plot für Käufe\n",
    "plt.scatter(test_data[:, 1], test_purchase_preds, alpha=0.5)\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.xlabel('Tatsächliche Käufe')\n",
    "plt.ylabel('Vorhergesagte Käufe')\n",
    "plt.title('Vorhersagegenauigkeit für Käufe')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7080d3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neue Daten zum Vorhersagen\n",
    "new_data = np.array([[0, 0, 10, 100]])\n",
    "\n",
    "# Vorhersage für Öffnungen und Käufe\n",
    "new_preds = model.predict(new_data)\n",
    "new_open\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f93bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Daten in ein Pandas-Dataframe laden\n",
    "data = pd.read_csv('sales_data.csv')\n",
    "\n",
    "# Aufteilen in Input-Features (Öffnungen) und Output-Features (Käufe)\n",
    "X = data[['Öffnungen']]\n",
    "y = data[['Käufe']]\n",
    "\n",
    "# Aufteilen in Trainings- und Testdaten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
